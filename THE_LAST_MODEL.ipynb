{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "THE LAST MODEL",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKmDERyazngu"
      },
      "source": [
        "# mounted the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z15QMAVMXIaj"
      },
      "source": [
        "path='/content/gdrive/My Drive/machine_learning/p_CNN/'\n",
        "path_resize='/content/gdrive/My Drive/machine_learning/resize_image_2/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb4g6p5HYni_"
      },
      "source": [
        "# this all the preparing the data with proper training data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7l8OrnyXIQh"
      },
      "source": [
        "# displayed bottom-left view\n",
        "from matplotlib.pyplot import imshow\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "testim = Image.open(path+\"bottom_left/IMG0 (2).jpg\", \"r\")\n",
        "testim_rotate = testim.transpose(Image.ROTATE_270)\n",
        "testim_resize = testim_rotate.resize((128, 128), Image.BOX)\n",
        "imshow(np.asarray(testim_resize))\n",
        "testim_resize.save(path_resize+\"bottom_left.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpdFmXAPXSWk"
      },
      "source": [
        "# displayed bottom_right view\n",
        "from matplotlib.pyplot import imshow\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "testim = Image.open(path+\"bottom_right/IMG0 (1).jpg\", \"r\")\n",
        "testim_rotate = testim.transpose(Image.ROTATE_90)\n",
        "testim_resize = testim_rotate.resize((1000, 1000), Image.BOX)\n",
        "imshow(np.asarray(testim_resize))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwA5LkfuXYc7"
      },
      "source": [
        "# displayed top_right view\n",
        "from matplotlib.pyplot import imshow\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "testim = Image.open(path+\"top_right/IMG0 (1).jpg\", \"r\")\n",
        "testim_rotate = testim.transpose(Image.ROTATE_90)\n",
        "testim_resize = testim_rotate.resize((1000, 1000), Image.BOX)\n",
        "imshow(np.asarray(testim_resize))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0GMWucaXdAo"
      },
      "source": [
        "# displayed top_left view\n",
        "from matplotlib.pyplot import imshow\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "testim = Image.open(path+\"top_left/IMG0 (1).jpg\", \"r\")\n",
        "testim_rotate = testim.transpose(Image.ROTATE_270)\n",
        "testim_resize = testim_rotate.resize((1000,1000), Image.BOX)\n",
        "imshow(np.asarray(testim_resize))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyCbnTSVXgRp"
      },
      "source": [
        "# displayed top_view view.\n",
        "from matplotlib.pyplot import imshow\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "testim = Image.open(path+\"top_view/IMG0 (1).jpg\", \"r\")\n",
        "testim_resize = testim.resize((1000,1000), Image.BOX)\n",
        "imshow(np.asarray(testim_resize))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGHlD0qmXlpp"
      },
      "source": [
        "# resizing and all done for bottom_left\n",
        "\n",
        "import os \n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "#read paths\n",
        "source_path=\"/content/gdrive/My Drive/machine_learning/p_CNN/bottom_left/\"\n",
        "dest_path=\"/content/gdrive/My Drive/machine_learning/resize_image_2/bottom_left/\"\n",
        "\n",
        "# declare count\n",
        "count=0\n",
        "# read all images from source path\n",
        "for count,image_file in enumerate(os.listdir(source_path)):\n",
        "    image_path = os.path.join(source_path, image_file)\n",
        "    # resizing of image\n",
        "    testim = Image.open(image_path, \"r\")\n",
        "    testim_rotate = testim.transpose(Image.ROTATE_270)\n",
        "    testim_resize = testim_rotate.resize((128,128), Image.BOX)\n",
        "    testim_resize.save(dest_path+str(count)+\".jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkDrQ73cX07d"
      },
      "source": [
        "# resizing and all done for bottom_right\n",
        "\n",
        "import os \n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "  \n",
        "#read paths\n",
        "source_path=\"/content/gdrive/My Drive/machine_learning/p_CNN/bottom_right/\"\n",
        "dest_path=\"/content/gdrive/My Drive/machine_learning/resize_image_2/bottom_right/\"\n",
        "\n",
        "# declare count\n",
        "count=0\n",
        "# read all images from source path\n",
        "for count,image_file in enumerate(os.listdir(source_path)):\n",
        "    image_path = os.path.join(source_path, image_file)\n",
        "    # resizing of image\n",
        "    testim = Image.open(image_path, \"r\")\n",
        "    testim_rotate = testim.transpose(Image.ROTATE_90)\n",
        "    testim_resize = testim_rotate.resize((128,128), Image.BOX)\n",
        "    testim_resize.save(dest_path+str(count)+\".jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ2Bgt6NX8WL"
      },
      "source": [
        "# resizing and all done for top_left\n",
        "\n",
        "import os \n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "#read paths\n",
        "source_path=\"/content/gdrive/My Drive/machine_learning/p_CNN/top_left/\"\n",
        "dest_path=\"/content/gdrive/My Drive/machine_learning/resize_image_2/top_left/\"\n",
        "\n",
        "# declare count\n",
        "count=0\n",
        "# read all images from source path\n",
        "for count,image_file in enumerate(os.listdir(source_path)):\n",
        "    image_path = os.path.join(source_path, image_file)\n",
        "    # resizing of image\n",
        "    testim = Image.open(image_path, \"r\")\n",
        "    testim_rotate = testim.transpose(Image.ROTATE_270)\n",
        "    testim_resize = testim_rotate.resize((128,128), Image.BOX)\n",
        "    testim_resize.save(dest_path+str(count)+\".jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_POn8i8IYASd"
      },
      "source": [
        "# resizing and all done for top_right\n",
        "\n",
        "import os \n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "#read paths\n",
        "source_path=\"/content/gdrive/My Drive/machine_learning/p_CNN/top_right/\"\n",
        "dest_path=\"/content/gdrive/My Drive/machine_learning/resize_image_2/top_right/\"\n",
        "\n",
        "# declare count\n",
        "count=0\n",
        "# read all images from source path\n",
        "for count,image_file in enumerate(os.listdir(source_path)):\n",
        "    image_path = os.path.join(source_path, image_file)\n",
        "    # resizing of image\n",
        "    testim = Image.open(image_path, \"r\")\n",
        "    testim_rotate = testim.transpose(Image.ROTATE_90)\n",
        "    testim_resize = testim_rotate.resize((128,128), Image.BOX)\n",
        "    testim_resize.save(dest_path+str(count)+\".jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqSWuHN_YFDq"
      },
      "source": [
        "# resizing and all done for top_view\n",
        "\n",
        "import os \n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "#read paths\n",
        "source_path=\"/content/gdrive/My Drive/machine_learning/p_CNN/top_view/\"\n",
        "dest_path=\"/content/gdrive/My Drive/machine_learning/resize_image_2/top_view/\"\n",
        "\n",
        "# declare count\n",
        "count=0\n",
        "# read all images from source path\n",
        "for count,image_file in enumerate(os.listdir(source_path)):\n",
        "    image_path = os.path.join(source_path, image_file)\n",
        "    print(image_path)\n",
        "    # resizing of image\n",
        "    testim = Image.open(image_path, \"r\")\n",
        "    testim_resize = testim.resize((128,128), Image.BOX)\n",
        "    testim_resize.save(dest_path+str(count)+\".jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26TYLddjYMI1"
      },
      "source": [
        "# preparing for preprocessing the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RK2I1LLZ2NI"
      },
      "source": [
        "# importing the data for the compiler \n",
        "\n",
        "import tensorflow as tf\n",
        "import os  \n",
        "import numpy as np\n",
        "from PIL import Image as pil_image\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "data_path = \"/content/gdrive/My Drive/machine_learning/resize_image_2/\"\n",
        "#labels = \n",
        "for label in os.listdir(data_path):\n",
        "    folder_path = os.path.join(data_path,label)  # path for data\n",
        "    for img in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, img)\n",
        "        img_open = pil_image.open(img_path)\n",
        "        np_image = np.array(img_open)\n",
        "        x.append(np_image)\n",
        "        y.append(label)      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3JcbNeMaCTt"
      },
      "source": [
        "# save the data after training \n",
        "#save it in pickle\n",
        "import pickle \n",
        "\n",
        "#a = {'x_train': 'y_train'}\n",
        "with open('/content/gdrive/My Drive/machine_learning/x.pkl', 'wb') as p:\n",
        "    pickle.dump(x, p, protocol=2)\n",
        "\n",
        "with open('/content/gdrive/My Drive/machine_learning/y.pkl', 'wb') as q:\n",
        "    pickle.dump(y, q, protocol=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M70QIZdHaLn8"
      },
      "source": [
        "# load the data again if you lost the runtime\n",
        "\n",
        "# this is only when new time spane is there to acess.\n",
        "import pickle\n",
        "\n",
        "with open('/content/gdrive/My Drive/machine_learning/y.pkl','rb') as p : \n",
        "     y = pickle.load(p)\n",
        "\n",
        "# with open('', 'wb') as q:\n",
        "with open('/content/gdrive/My Drive/machine_learning/x.pkl','rb') as p : \n",
        "    x = pickle.load(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmzxRZxGaXAs"
      },
      "source": [
        "# print to cross the data is loaded or not\n",
        "\n",
        "print(len(x))\n",
        "print(len(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UBxkv2yagO7"
      },
      "source": [
        "# split the data in classes as x_train,y_train,x_test,y_test,x_val,y_val\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2, random_state=42, shuffle=True)\n",
        "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.2, random_state=42, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hvZA-OJbBkI"
      },
      "source": [
        "# lebal the classes for y_train\n",
        "\n",
        "label_name=set(y_train)\n",
        "#answer=5\n",
        "print(label_name)\n",
        "num_classes=len(label_name)\n",
        "print(num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPITfDknbOL7"
      },
      "source": [
        "#Print the data type of x_train,y_train,x_test,y_test,x_val,y_val\n",
        "\n",
        "print(type(x_train))\n",
        "print(type(y_train))\n",
        "print(type(x_test))\n",
        "print(type(y_test))\n",
        "print(type(x_val))\n",
        "print(type(y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_sDZIqccSJG"
      },
      "source": [
        "# To check the correct data is input or not\n",
        "\n",
        "print(len(x_train))\n",
        "print(len(y_train))\n",
        "print(len(x_val))\n",
        "print(len(y_val))\n",
        "print(len(x_test))\n",
        "print(len(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acmsSqfYcod0"
      },
      "source": [
        "#array for x_train, x_val, x_test\n",
        "#convert to array\n",
        "\n",
        "import numpy as np\n",
        "x_train_arr = np.asarray(x_train)\n",
        "print(x_train_arr.shape)\n",
        "\n",
        "x_test_arr = np.asarray(x_test)\n",
        "print(x_test_arr.shape)\n",
        "\n",
        "x_val_arr = np.asarray(x_val)\n",
        "print(x_val_arr.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkuYe1YZc1U1"
      },
      "source": [
        "#save the x_train, x_val, x_test for to avoide more runtime\n",
        "\n",
        "np.save('/content/gdrive/My Drive/machine_learning/x_train.npy', x_train_arr)\n",
        "np.save('/content/gdrive/My Drive/machine_learning/x_test.npy', x_test_arr)\n",
        "np.save('/content/gdrive/My Drive/machine_learning/x_val.npy', x_val_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj5BVgYac9mm"
      },
      "source": [
        "# Load back to compiler from drive\n",
        "\n",
        "import numpy as np\n",
        "x_train_arr = np.load('/content/gdrive/My Drive/machine_learning/x_train.npy')\n",
        "x_test_arr = np.load('/content/gdrive/My Drive/machine_learning/x_test.npy')\n",
        "x_val_arr = np.load('/content/gdrive/My Drive/machine_learning/x_val.npy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHjEFV3QdKny"
      },
      "source": [
        "# to cross check the data is there or not\n",
        "# for x_train,x_test,x_val\n",
        "\n",
        "print(x_train_arr.shape)\n",
        "print(x_train_arr.shape)\n",
        "print(x_train_arr.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qHYNqRK4BT5"
      },
      "source": [
        "#array for y_train,y_test,y_val\n",
        "# convert to array\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "import numpy as np\n",
        "\n",
        "code_y_train = np.array(y_train)\n",
        "vec_y_train = label_encoder.fit_transform(code_y_train)\n",
        "\n",
        "code_y_test = np.array(y_test)\n",
        "vec_y_test = label_encoder.fit_transform(code_y_test)\n",
        "\n",
        "code_y_val = np.array(y_val)\n",
        "vec_y_val = label_encoder.fit_transform(code_y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7AEaNzz4U6T"
      },
      "source": [
        "# print to the classes and the type of y_train,y_test,y_val\n",
        "\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "\n",
        "y_train_arr = np_utils.to_categorical(vec_y_train, num_classes)\n",
        "print(y_train_arr.shape)\n",
        "print(type(y_train_arr))\n",
        "\n",
        "y_test_arr = np_utils.to_categorical(vec_y_test, num_classes)\n",
        "print(y_test_arr.shape)\n",
        "print(type(y_test_arr))\n",
        "\n",
        "y_val_arr = np_utils.to_categorical(vec_y_val, num_classes)\n",
        "print(y_val_arr.shape)\n",
        "print(type(y_val_arr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAqVRnAm4o8o"
      },
      "source": [
        "# save the value of y_train,y_test,y_val\n",
        "\n",
        "np.save('/content/gdrive/My Drive/machine_learning/y_train.npy', y_train_arr)\n",
        "np.save('/content/gdrive/My Drive/machine_learning/y_test.npy',y_test_arr)\n",
        "np.save('/content/gdrive/My Drive/machine_learning/y_val.npy', y_val_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLxJBNgL43GV"
      },
      "source": [
        "# load the value of all the y_train,y_test,y_val to save the runtime\n",
        "\n",
        "y_train_arr = np.load('/content/gdrive/My Drive/machine_learning/y_train.npy')\n",
        "y_test_arr = np.load('/content/gdrive/My Drive/machine_learning/y_test.npy')\n",
        "y_val_arr = np.load('/content/gdrive/My Drive/machine_learning/y_val.npy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO9qp_0V5Dyt"
      },
      "source": [
        "# cross check wheather the values are load on compiler or not\n",
        "# vales of y_train,y_test,y_val \n",
        "\n",
        "print(type(y_train_arr))\n",
        "print(y_train_arr.shape)\n",
        "\n",
        "print(type(y_test_arr))\n",
        "print(y_test_arr.shape)\n",
        "\n",
        "print(type(y_val_arr))\n",
        "print(y_val_arr.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4hMz3Za5pTu"
      },
      "source": [
        "# divide the main x_train,x_test,x_val by 255 to set more accurate vale\n",
        "# print the vale x_train,x_test,x_val\n",
        "# maintion vale of the batch_size\n",
        "\n",
        "X_train=x_train_arr/255\n",
        "X_val=x_val_arr/255\n",
        "X_test=x_test_arr/255\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)\n",
        "\n",
        "batch_size=32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXTJ-Bob6Pk8"
      },
      "source": [
        "# the main CNN code for the model\n",
        "\n",
        "from keras.models import Sequential   \n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import activations\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Conv2D(16, (5, 5), padding='same', activation='relu', input_shape=(128,128,3)))    #used to name the model with the training info\n",
        "model.add(MaxPooling2D(pool_size=(16, 16)))\n",
        "model.add(Dropout(0.6)) \n",
        "\n",
        "model.add(Conv2D(16, (5, 5), padding='same', activation='relu'))    #used to name the model with the training info\n",
        "model.add(MaxPooling2D(pool_size=(8, 8)))\n",
        "model.add(Dropout(0.2)) \n",
        "\n",
        "\n",
        "model.add(Flatten())  #tthis are input layers\n",
        "model.add(Dense(16, activation=tf.nn.relu))    #past some parametors for layers and have a  activation fuction which help the nuron to fire\n",
        "#model.add(Dense(num_classes))\n",
        "model.add(Dense(num_classes, activation=tf.nn.softmax))  # SM for probability\n",
        "#this the architecture for train the model is above.....\n",
        "# check model structure and the number of parameters\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(),  #default go to optimizer is used adam which very .\n",
        "              loss=keras.losses.categorical_crossentropy,  #used too categorical the data \n",
        "              metrics=[\"accuracy\"])   \n",
        "\n",
        "model.fit(X_train,y_train_arr,batch_size=batch_size,steps_per_epoch =30,validation_data=(X_val, y_val_arr),validation_steps = 15\n",
        "          , epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WCNR9CP6Yeh"
      },
      "source": [
        "# result the model accuracy and loss\n",
        "\n",
        "results = model.evaluate(X_test, y_test_arr, batch_size=32)\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVUbwH9_6jQI"
      },
      "source": [
        "# save the model to drive\n",
        "\n",
        "model.save('/content/gdrive/My Drive/machine_learning/model_out')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b13_qQkU6pFJ"
      },
      "source": [
        "# load the model if require from drive\n",
        "\n",
        "model = keras.models.load_model('path/to/location')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad6TUWHVdNwa"
      },
      "source": [
        "# to plot the graph for more accuracy \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(y_p.history['accuracy'], label='accuracy')\n",
        "plt.plot(y_p.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.1, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_train, y_train_arr, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}